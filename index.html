<!DOCTYPE html>
<html lang ="ja">
<head>
    <meta charset="UTF-8">
    <link rel="stylesheet" href="style.css">
    <title>石策竜喜のホームページ(@github)</title>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
    japonicus sum.
    <header id ="header">
        <h1>石策竜喜のホームページ(@github)</h1>
    </header>
    <h2>統計学</h2>
<!--        <aside>
            <p>アインシュタインは \( E=mc^2 \) の公式を導きました。</p>
            \(
                \begin{pmatrix}
                2 & 3 \\
                2 & 4 \\
                3 & 7 
                \end{pmatrix}
                \begin{pmatrix}
                x_{1} \\
                x_{2}
                \end{pmatrix}
                =
                \begin{pmatrix}
                2x_{1}+3x_{2} \\
                2x_{1}+4x_{2} \\
                3x_{1}+7x_{2}
                \end{pmatrix}
                \) <br>
                \( {}_n C_k \) <br>
                \( \displaystyle {}_n C_k =\frac{n!}{k!(n-k)! }, 0!=1 \)

                    </aside>
            <main>
            <h2>歴史</h2>
            <h3>古人類</h3>
            <a href="Strepsirrhini.html"></a><br>
    
            <h3>日本史</h3>
            <a href="pseudo_upper_paleolithic.html"></a><br>
    -->
    <p></p>
    <p>偶然性を伴った試行或いは観測を行うことを確率実験(radom experiment)という。1つの確立実験に対して、その可能な起こりうる結果の全体を標本空間(sample space)、事象空間(event space)または全事象と呼ぶ。(以下、単にΩと書けば全事象を指す。また、「事象」と「集合」を同じ意味で用いる。)標本空間の各要素を標本点(sample point)または根源事象(elementary event)という。Ωの部分集合は事象と呼ばれる。事象Aが起こるということは、集合Aに含まれる標本点のどれかが起こることである。各標本点について、その生起する確率を決めることができる。</p>
    <p>確率の決め方には、以下の4つの方法がある。
    <dl>
        <dt>先験的アプローチ</dt>
        <dd>起こり得るあらゆる場合が同じように確からしく、かつ互いに排反であるとき、あるゆる場合の数をn(Ω), 事象Aが起こる場合の数をn(Ω)とすると、事象Aが起こる確率はn(A)/n(Ω)である。このように定められる確率を先験的確率(a priori probability)という。</dd>
        <dd>例えば、歪みの無い硬貨を投げた時に表が出る確率と裏が出る確率がともに1/2となること、歪みの無い六面体骰子を投げた時に各々の目が出る確率が全て1/6になるとことは、実験をするまでもなく当然のこととして認めてよい。よってこれらは先験的確率である。高校の数学Aで扱う確率は、全て先験的確率である。</dd>
        <dt>経験的アプローチ</dt>
        <dd>歪んだ骰子を振って、1の目が出る確率を考える。骰子を振った回数をnとし、そのうち1の目が出た回数を\(n_a\)とすると、nを大きくするに従い、\(\frac{n_a}{n}\)はある一定の値に近づくと考えられる。その値が1の目が出る確率とするのである。すなわち、
            \begin{eqnarray}
            P(A)=\lim_{n \to \infty}\frac{n_a}{n}
            \end{eqnarray}
    
        </dd></dd>
    </dl>
    </p>
    <dl>
    <dt>算術平均</dt>
    <dd>\begin{eqnarray}
        \frac{1}{n}\sum_{i=1}^n x_i = \frac{x_1 + x_2 +  \cdots + x_n}{n} 
        \end{eqnarray}
    </dd>
    <p>算術平均の性質</p>
    <ol>
        <li>平均からの偏差の和は0となる。すなわち、<br>
        \begin{eqnarray}
        \sum_{i=1}^n (x_i - \bar{x}) = 0 
        \end{eqnarray}
        </li>
        <li>偏差の平方和の中で最小となるのは、平均からの偏差の平方和である。すなわち、任意のaについて、<br>
            \begin{eqnarray}
            \sum_{i=1}^n (x_i - \bar{x})^2 ≤ \sum_{i=1}^n (x_i - a)^2 
            \end{eqnarray}
    
        </li>
    </ol>
    <p>性質1の証明</p>
    \begin{eqnarray}
    \sum_{i=1}^n (x_i - \bar{x}) = \sum_{i=1}^n x_i - \bar{x} \sum_{i=1}^n = n\bar{x} - \bar{x}n = 0 
    \end{eqnarray}
    <p>性質2の証明</p>
    \begin{eqnarray}
    \sum_{i=1}^n (x_i - \bar{x})^2 
    = \sum_{ i = 1 }^{ n } {(x_i - \bar{x}) - (\bar{x} - a)}^2  
    = \sum_{ i = 1 }^{ n } ((x_i - \bar{x})^2 + 2(x_i - \bar{x})(\bar{x} - a) + (\bar{x} - a)^2)
    = \sum_{ i = 1 }^{ n } (x_i - \bar{x})^2 + 2\sum_{ i = 1 }^{ n } (x_i - \bar{x})(\bar{x} - a) + \sum_{ i = 1 }^{ n } (\bar{x} - a)^2
    = \sum_{ i = 1 }^{ n } (x_i - \bar{x})^2 + 2(\bar{x} - a)\sum_{ i = 1 }^{ n } (x_i - \bar{x}) + n(\bar{x} - a)^2
    = \sum_{ i = 1 }^{ n } (x_i - \bar{x})^2 + n(\bar{x} - a)^2
    ≤ \sum_{i=1}^n (x_i - a)^2 
    \end{eqnarray}
    <br>性質1により、第2項は0。等号成立は、\(\bar{x} - a = 0 \)のとき。
    <dt>分散</dt>
    <dd>\begin{eqnarray}
        \frac{1}{n}\sum_{i=1}^n (x_i - \bar{x})^2 
        \end{eqnarray}
    </dd>
</dl>
<p>分散はまた、
        \begin{eqnarray}
        \frac{1}{n}\sum_{i=1}^n x_i^2 - \bar{x}^2
        \end{eqnarray}
    によっても計算できる。
    </p>
    <p>証明
        \begin{eqnarray}
        \frac{1}{n}\sum_{i=1}^n (x_i - \bar{x})^2 
        = \frac{1}{n}\sum_{i=1}^n (x_i^2 -2\bar{x}x_i + \bar{x}^2)
        = \frac{1}{n}(\sum_{i=1}^n x_i^2 -2\bar{x}\sum_{i=1}^n x_i + \bar{x}^2\sum_{i=1}^n )
        = \frac{1}{n}(\sum_{i=1}^n x_i^2 -2\bar{x}*n\bar{x} + n\bar{x}^2 )
        = \frac{1}{n}(\sum_{i=1}^n x_i^2 - n\bar{x}^2 )
        = \frac{1}{n}\sum_{i=1}^n x_i^2 - \bar{x}^2
        \end{eqnarray}
    </p>
    <p>後者の計算方法は、手計算する場合にも概して定義通りの計算より簡単であるが、特に計算機で計算する場合、誤差を少なくできる利点がある。</p>
    <dd>標本分散</dd>
    <dt>\begin{eqnarray}
        \frac{1}{n-1}\sum_{i=1}^n (x_i - \bar{x})^2 
        \end{eqnarray}
    </dt>

    <p>導出
    \begin{eqnarray}
    \sum_{ i = 1 }^{ n } (x_i - μ)^2
    = \sum_{ i = 1 }^{ n } {(x_i - \bar{x}) - (\bar{x} - μ)}^2 
    = \sum_{ i = 1 }^{ n } (x_i - \bar{x})^2 + 2\sum_{ i = 1 }^{ n } (x_i - \bar{x})(\bar{x} - μ) + \sum_{ i = 1 }^{ n } (\bar{x} - μ)^2
    = \sum_{ i = 1 }^{ n } (x_i - \bar{x})^2 + n(\bar{x} - μ)^2
    \end{eqnarray}
    </p>
    <p>両辺の期待値を取って、
    \begin{eqnarray}
    E(\sum_{ i = 1 }^{ n } (x_i - μ)^2) = E(\sum_{ i = 1 }^{ n } (x_i - \bar{x})^2) + nE((\bar{x} - μ)^2)
    \end{eqnarray}
    \begin{eqnarray}
    \sum_{ i = 1 }^{ n } V(x_i) = E(\sum_{ i = 1 }^{ n } (x_i - \bar{x})^2) + nV(\bar{x})
    \end{eqnarray}
    </p>
    <p>ここで、
    \begin{eqnarray}
    V(x_1) = V(x_2) = \cdots = V(x_n) = \sigma^2
    \end{eqnarray}
    \begin{eqnarray}
    V(\bar{x}) = V(\frac{x_1 + x_2 + \cdots + x_n}{n}) = V(\frac{x_1}{n}) + V(\frac{x_2}{n}) + \cdots + V(\frac{x_n}{n}) = \frac{1}{n^2}\sigma^2 + \frac{1}{n^2}\sigma^2 + \cdots + \frac{1}{n^2}\sigma^2 = \frac{1}{n}\sigma^2
    \end{eqnarray}
    であるから、
    \begin{eqnarray}
    n\sigma^2 = E(\sum_{ i = 1 }^{ n } (x_i - \bar{x})^2) + n\frac{1}{n}\sigma^2
    \end{eqnarray}
    \begin{eqnarray}
    E(\sum_{ i = 1 }^{ n } (x_i - \bar{x})^2) = n\sigma^2 - \sigma^2 = (n-1)\sigma^2
    \end{eqnarray}
    ここで、
    \begin{eqnarray}
    s^2 = E(\frac{\sum_{ i = 1 }^{ n } (x_i - \bar{x})^2 }{n-1})
    \end{eqnarray}
    とおくと、
    \begin{eqnarray}
    E(s^2) = \sigma^2
    \end{eqnarray}
    となる。これから分かるように、「標本分散」という呼び方は若干誤導的で、所謂「標本分散」とは、「標本の分散」ではなく、「その期待値が母分散となるような、標本から計算されるある値」のことである。なお、「標本分散」は、不偏分散 unbiased variance とも呼ばれる。こちらの方が、誤解は招きにくい呼び方かもしれない。(ただし、名前からそれが何なののか推測できなくはあるが。)
 </p>
    <dt>確率変数</dt>
    <dd>試行がもたらす事象を実数に対応させる関数を確率変数という。この関数が出力する値のことを確率変数の実現値という。(ただし、誤解の余地がなければ、確率変数の実現値のことを単に確率変数ということもある。)</dd>
    <p>標本空間に含まれる事象が有限個の場合、この標本空間に関して定められた確率変数は、根源事象と個々の実現値を一対一対応させる。すなわち、根源事象\[a_1,a_2,\ldots,a_n\]に対して、確率変数の出力結果(実現値)\[x_1,x_2,\ldots,x_n\]を対応させることができる。このような確率変数を、離散型確率変数(discrete random varible)と呼ぶ。</p>
    <p>この確率変数の出力結果それぞれについて、その値が生じる確率を定めることができる。確率変数の出力結果(実現値)を入力とし、その確率を出力とする関数を確率関数という。なお、異なる実現値が同じ確率で生じることがあるので、確率関数は一般に一対一対応ではない。</p>
    <p>なぜ、事象とその発生確率を直接に結び付けず、間に確率変数というものを介在させるかというと、確率変数の実現値は実数なので、期待値の計算など、数値的な処理が可能になるという利点があるからである。</p>
    <p>例1: 硬貨を投げて出る面を標本空間とすると、根源事象は「表」、「裏」の2つである。ここで、生起した根源事象が「表」ならば1、「裏」ならば0 を出力する確率変数をXとすると、X(表)=1, X(裏)=0 と書くことができる。ひとたび確率変数を定めてしまうと、元の根源事象について言及する必要はもうないので、単に X=0,1 と書いて、Xの出力結果(実現値)が0または1であることを示してもよい。そして、確率関数をPとすると、\[P(0)=\frac{1}{2}, P(0)=\frac{1}{2}\]と定めることができる。表にすると次のようになる。
        <table>
            <tr><th>根源事象</th><td>表</td><td>裏</td></tr>
            <tr><th>確率変数 X</th><td>1</td><td>0</td></tr>
            <tr><th>確率 P</th><td>1/2</td><td>1/2</td></tr>
        </table>
    1段目に2段目を対応させるのが確率変数、2段目に3段目を対応させるのが確率関数である。</p>
    <p>例2: 骰子を振って出る目を根源事象とすると、
        <table>
            <tr><th>根源事象</th><td>1の目</td><td>2の目</td><td>3の目</td><td>4の目</td><td>5の目</td><td>6の目</td></tr>
            <tr><th>確率変数 X</th><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td></tr>
            <tr><th>確率 P</th><td>1/6</td><td>1/6</td><td>1/6</td><td>1/6</td><td>1/6</td><td>1/6</td></tr>
        </table>
    </p>
    <p>以上をまとめて、</p>
    <p>確率変数がとるn個の有限な実数値に対して、確率関数Pは
        \begin{eqnarray}
        P(x_1) = p_1, P(x_2) = p_2, \ldots, P(x_n) = p_n 
        \end{eqnarray}
    をとり、他の実数については\(P(x)=0\)。ただし、\(0&ltp_i≤1 (i=1,\ldots,n) \) </p>

    <p>1辺の長さLの立方体の容器の中で運動する気体分子を考える。<br>
    容器の辺と平行にx軸、y軸、z軸を取る。容器の中の1つの気体分子に着目し、この分子が速度
    \begin{eqnarray}
    v= 
    \begin{pmatrix}
    v_x \\ v_y \\ v_z
    \end{pmatrix}
    \end{eqnarray}
    で運動しているとする。まず、x軸方向の運動を考える。<br>
    yz平面に平行な壁の1つを壁Aとする。分子が壁Aと衝突した前後の運動量変化は、衝突前にx軸の正方向に運動していたとして、
    \begin{eqnarray}
    -mv_x-mv_x=-2mv_x (kg m/s) 
    \end{eqnarray}
    よって、壁Aがこの衝突によって受ける力積は\(2mv_x\)
    この分子が壁Aと衝突する単位時間当たりの衝突回数は、
    \begin{eqnarray}
    \frac{1}{\frac{2L}{v_x}} = \frac{v_x}{2L} (\frac{1}{s})
    \end{eqnarray}
    単位時間にこの分子が壁Aに与える力積(=壁)
    </p>
    <div id="container">
                </main>
    </div>
    <footer>

    </footer>
</body>
</html>
